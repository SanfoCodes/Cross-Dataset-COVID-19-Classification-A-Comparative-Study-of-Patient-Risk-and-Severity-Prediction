{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faaa9ff5-d86a-4274-ae92-4109d51e752e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import load_datasets, basic_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af630a6-860d-45c5-86da-594b7fa9da88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = load_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e8937a-19fd-4313-84d1-4ca49f14a7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(df, target_column):\n",
    "    df = basic_preprocess(df, target_column)\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier()\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nðŸ”¸ {name} on target `{target_column}`\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ff3b95-edd2-4272-8d06-7ad27bd7f335",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Logistic Regression on target `Severity_Severe`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     47641\n",
      "           1       1.00      1.00      1.00     15719\n",
      "\n",
      "    accuracy                           1.00     63360\n",
      "   macro avg       1.00      1.00      1.00     63360\n",
      "weighted avg       1.00      1.00      1.00     63360\n",
      "\n",
      "\n",
      "ðŸ”¸ Random Forest on target `Severity_Severe`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     47641\n",
      "           1       1.00      1.00      1.00     15719\n",
      "\n",
      "    accuracy                           1.00     63360\n",
      "   macro avg       1.00      1.00      1.00     63360\n",
      "weighted avg       1.00      1.00      1.00     63360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = datasets['dataset_1'].copy()\n",
    "train_and_evaluate(df1, target_column='Severity_Severe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0be965e-839c-4ca1-b4d8-48fab3184708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Logistic Regression on target `high_death`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1801\n",
      "           1       1.00      1.00      1.00      1821\n",
      "\n",
      "    accuracy                           1.00      3622\n",
      "   macro avg       1.00      1.00      1.00      3622\n",
      "weighted avg       1.00      1.00      1.00      3622\n",
      "\n",
      "\n",
      "ðŸ”¸ Random Forest on target `high_death`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1801\n",
      "           1       1.00      1.00      1.00      1821\n",
      "\n",
      "    accuracy                           1.00      3622\n",
      "   macro avg       1.00      1.00      1.00      3622\n",
      "weighted avg       1.00      1.00      1.00      3622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = datasets['dataset_2'].copy()\n",
    "\n",
    "# Convert 'Deaths' column to numeric if needed\n",
    "df2['Deaths'] = pd.to_numeric(df2['Deaths'], errors='coerce')\n",
    "\n",
    "# Drop any rows where Deaths is missing\n",
    "df2 = df2.dropna(subset=['Deaths'])\n",
    "\n",
    "# Create the binary target column before preprocessing\n",
    "median_death = df2['Deaths'].median()\n",
    "df2['high_death'] = (df2['Deaths'] > median_death).astype(int)\n",
    "\n",
    "# Now train using that new column\n",
    "train_and_evaluate(df2, target_column='high_death')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdbf50d-8424-4e63-8b60-d80ef69a90bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Logistic Regression on target `high_death`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5060\n",
      "           1       1.00      1.00      1.00      4754\n",
      "\n",
      "    accuracy                           1.00      9814\n",
      "   macro avg       1.00      1.00      1.00      9814\n",
      "weighted avg       1.00      1.00      1.00      9814\n",
      "\n",
      "\n",
      "ðŸ”¸ Random Forest on target `high_death`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5060\n",
      "           1       1.00      1.00      1.00      4754\n",
      "\n",
      "    accuracy                           1.00      9814\n",
      "   macro avg       1.00      1.00      1.00      9814\n",
      "weighted avg       1.00      1.00      1.00      9814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = datasets['dataset_3'].copy()\n",
    "df3['high_death'] = (df3['Deaths'] > df3['Deaths'].median()).astype(int)\n",
    "train_and_evaluate(df3, target_column='high_death')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e06dc5-c0c1-460c-93fc-24cb9629d455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Logistic Regression on target `vaccinated`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85     12950\n",
      "           1       0.56      0.44      0.50      4353\n",
      "\n",
      "    accuracy                           0.77     17303\n",
      "   macro avg       0.69      0.66      0.67     17303\n",
      "weighted avg       0.76      0.77      0.76     17303\n",
      "\n",
      "\n",
      "ðŸ”¸ Random Forest on target `vaccinated`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     12950\n",
      "           1       0.76      0.73      0.74      4353\n",
      "\n",
      "    accuracy                           0.87     17303\n",
      "   macro avg       0.83      0.82      0.83     17303\n",
      "weighted avg       0.87      0.87      0.87     17303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = datasets['dataset_4'].copy()\n",
    "df4['vaccinated'] = (df4['total_vaccinations'] > df4['total_vaccinations'].median()).astype(int)\n",
    "train_and_evaluate(df4, target_column='vaccinated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b13f0362-fc2d-4a4e-9425-70213a681d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Logistic Regression on target `ICU`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.10      0.17        60\n",
      "           2       0.92      0.99      0.96       668\n",
      "          97       1.00      1.00      1.00      3236\n",
      "          99       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           0.99      4000\n",
      "   macro avg       0.88      0.77      0.78      4000\n",
      "weighted avg       0.98      0.99      0.98      4000\n",
      "\n",
      "\n",
      "ðŸ”¸ Random Forest on target `ICU`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.22      0.30        60\n",
      "           2       0.93      0.98      0.95       668\n",
      "          97       1.00      1.00      1.00      3236\n",
      "          99       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           0.98      4000\n",
      "   macro avg       0.85      0.80      0.81      4000\n",
      "weighted avg       0.98      0.98      0.98      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = datasets['dataset_5'].copy()\n",
    "\n",
    "# Sample 20,000 rows for quick modeling\n",
    "df5_sample = df5.sample(n=20000, random_state=42)\n",
    "\n",
    "train_and_evaluate(df5_sample, target_column='ICU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b294db-242e-42d1-8740-95c811555405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c1b7d-90e0-450b-990d-843978876dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
