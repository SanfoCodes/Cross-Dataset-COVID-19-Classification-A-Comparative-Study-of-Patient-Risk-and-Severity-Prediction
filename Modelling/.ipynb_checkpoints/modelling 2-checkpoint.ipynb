{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b3e7ec-5665-4359-b048-efecb4b473ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_datasets, basic_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f855044-9a33-4329-b860-8a1ce1d25053",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c859dfec-e5ab-4dca-8abd-58f7b5b95b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_nb_xgb(df, target_column):\n",
    "    df = basic_preprocess(df, target_column)\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nðŸ”¸ {name} on target `{target_column}`\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66306e4c-61d8-400c-9253-7ea130f2f1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Naive Bayes on target `Severity_Severe`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     47641\n",
      "           1       1.00      1.00      1.00     15719\n",
      "\n",
      "    accuracy                           1.00     63360\n",
      "   macro avg       1.00      1.00      1.00     63360\n",
      "weighted avg       1.00      1.00      1.00     63360\n",
      "\n",
      "\n",
      "ðŸ”¸ XGBoost on target `Severity_Severe`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     47641\n",
      "           1       1.00      1.00      1.00     15719\n",
      "\n",
      "    accuracy                           1.00     63360\n",
      "   macro avg       1.00      1.00      1.00     63360\n",
      "weighted avg       1.00      1.00      1.00     63360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = datasets['dataset_1'].copy()\n",
    "train_and_evaluate_nb_xgb(df1, target_column='Severity_Severe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d82f36-4c46-4ed7-b39c-90dbb629b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Naive Bayes on target `high_death`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1801\n",
      "           1       0.98      0.97      0.98      1821\n",
      "\n",
      "    accuracy                           0.98      3622\n",
      "   macro avg       0.98      0.98      0.98      3622\n",
      "weighted avg       0.98      0.98      0.98      3622\n",
      "\n",
      "\n",
      "ðŸ”¸ XGBoost on target `high_death`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1801\n",
      "           1       1.00      1.00      1.00      1821\n",
      "\n",
      "    accuracy                           1.00      3622\n",
      "   macro avg       1.00      1.00      1.00      3622\n",
      "weighted avg       1.00      1.00      1.00      3622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = datasets['dataset_2'].copy()\n",
    "\n",
    "# Convert 'Deaths' column to numeric if needed\n",
    "df2['Deaths'] = pd.to_numeric(df2['Deaths'], errors='coerce')\n",
    "\n",
    "# Drop any rows where Deaths is missing\n",
    "df2 = df2.dropna(subset=['Deaths'])\n",
    "\n",
    "# Create the binary target column before preprocessing\n",
    "median_death = df2['Deaths'].median()\n",
    "df2['high_death'] = (df2['Deaths'] > median_death).astype(int)\n",
    "\n",
    "# Now train using that new column\n",
    "train_and_evaluate_nb_xgb(df2, target_column='high_death')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959ab403-bd17-42ba-bebc-fc6437d00fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Naive Bayes on target `high_death`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87      5060\n",
      "           1       0.97      0.70      0.81      4754\n",
      "\n",
      "    accuracy                           0.84      9814\n",
      "   macro avg       0.87      0.84      0.84      9814\n",
      "weighted avg       0.87      0.84      0.84      9814\n",
      "\n",
      "\n",
      "ðŸ”¸ XGBoost on target `high_death`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5060\n",
      "           1       1.00      1.00      1.00      4754\n",
      "\n",
      "    accuracy                           1.00      9814\n",
      "   macro avg       1.00      1.00      1.00      9814\n",
      "weighted avg       1.00      1.00      1.00      9814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = datasets['dataset_3'].copy()\n",
    "df3['high_death'] = (df3['Deaths'] > df3['Deaths'].median()).astype(int)\n",
    "\n",
    "train_and_evaluate_nb_xgb(df3, target_column='high_death')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0010cb68-5ae5-49eb-bd1a-cbf6be7cfa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Naive Bayes on target `vaccinated`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88     12950\n",
      "           1       0.85      0.24      0.37      4353\n",
      "\n",
      "    accuracy                           0.80     17303\n",
      "   macro avg       0.82      0.61      0.63     17303\n",
      "weighted avg       0.81      0.80      0.75     17303\n",
      "\n",
      "\n",
      "ðŸ”¸ XGBoost on target `vaccinated`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     12950\n",
      "           1       0.77      0.67      0.72      4353\n",
      "\n",
      "    accuracy                           0.87     17303\n",
      "   macro avg       0.83      0.80      0.82     17303\n",
      "weighted avg       0.86      0.87      0.86     17303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = datasets['dataset_4'].copy()\n",
    "df4['vaccinated'] = (df4['total_vaccinations'] > df4['total_vaccinations'].median()).astype(int)\n",
    "train_and_evaluate_nb_xgb(df4, target_column='vaccinated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d5e23d0-bb51-48af-997f-e85dcd39b863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU\n",
      "0    175685\n",
      "1     16858\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ”¸ Naive Bayes on target `ICU`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95       364\n",
      "           1       0.22      0.06      0.09        36\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.57      0.52      0.52       400\n",
      "weighted avg       0.85      0.90      0.87       400\n",
      "\n",
      "\n",
      "ðŸ”¸ XGBoost on target `ICU`\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       364\n",
      "           1       0.40      0.28      0.33        36\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.67      0.62      0.64       400\n",
      "weighted avg       0.88      0.90      0.89       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = datasets['dataset_5'].copy()\n",
    "\n",
    "# Keep only rows with ICU = 1 or 2\n",
    "df5 = df5[df5['ICU'].isin([1, 2])]\n",
    "\n",
    "# Recode: 1 = ICU, 2 = No ICU\n",
    "df5['ICU'] = df5['ICU'].map({1: 1, 2: 0})\n",
    "\n",
    "# Optional: Check balance\n",
    "print(df5['ICU'].value_counts())\n",
    "\n",
    "# Sample for faster training\n",
    "df5_sample = df5.sample(n=2000, random_state=42)\n",
    "\n",
    "# Train models\n",
    "train_and_evaluate_nb_xgb(df5_sample, target_column='ICU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a3fb2-bd00-4edd-86b3-c0b15d0d37f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
